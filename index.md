This page contains audio samples generated by our voice style transfer framework, created for our final project for the Audio Processing and Indexing 2021 course at leiden university. For this project we investigate voice style transfer using the [AutoVC](https://github.com/auspicious3000/autovc) framework.

The table below contains conversion samples between speakers from the VCTK dataset. We define the following elements:

* **AutoVC:** The pretrained AutoVC network uploaded by the authors.
* **New AutoVC:** Retrained AutoVC network with MelGAN spectograms.
* **Griffin:** A [Griffin-Lim based](https://librosa.org/doc/main/generated/librosa.griffinlim.html) vocoder method.
* **WaveNet:** A [WaveNet](https://github.com/r9y9/wavenet_vocoder) vocoder pretrained on VCTK by the AutoVC authors.
* **MelGAN:** A Multi-band [MelGAN](https://github.com/kan-bayashi/ParallelWaveGAN) vocoder pretrained on VCTK

<style>
	.alignright {
		text-align: right;
		float:right;
	}
</style>

## Short Samples
We notice that AutoVC + WaveNet performs well on short samples. However, its conversion times are very long. Our first solution was to replace the WaveNet vocoder by a Griffin-Lim algorithm. This significantly improved conversion speed, at the cost of audio quality. We aimed to improve this by introducing the Multiband MelGAN model. This required us to retrain the AutoVC model to fit the Mel-Spectrogram format required for this vocoder. This improves audio quality significantly compared to the Griffin-Lim algorithm. However, the voice style of the converted samples was found to differ slightly from the target speaker.

| Source Speaker | Target Speaker | Results |
|----|----|----|
| p225 (Female) <br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001.wav'></audio> | p225 (Female) <br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001.wav'></audio> | AutoVC + WaveNet (Baseline)<span class='alignright'>(320.76s)</span> <br>  <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xp225_old_wavenet.wav'></audio> AutoVC + Griffin <span class='alignright'>(1.19s)</span><br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xp225_old_griffin.wav'></audio> <br> AutoVC + MelGAN <span class='alignright'>(1.07s)</span><br>  <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xp225_old_melgan.wav'></audio> <br> New AutoVC + MelGAN <span class='alignright'>(0.80s)</span><br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xp225_new_melgan.wav'></audio> |
| | p226 (Male) <br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p226_003.wav'></audio> | AutoVC + WaveNet <span class='alignright'>(306.57s)</span> <br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xp226_old_wavenet.wav'></audio> <br> New AutoVC + MelGAN <span class='alignright'>(1.08s)</span> <br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xp226_new_melgan.wav'></audio> |
| | Wouter (Male) <br>  <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/Wouter_this_is_a_testsentence.wav'></audio> |AutoVC + WaveNet  <span class='alignright'>(313.75s)</span> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xWouter_wavenet.wav'></audio> AutoVC + MelGAN  <span class='alignright'>(1.31s)</span> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001xWouter_new_melgan.wav'></audio>|

## Longer Samples

| Source Speaker | Target Speaker | Results |
|----|----|----|
|p226 (Male)<br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p226_003.wav'></audio>| p225 (Female) <br>  <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_001.wav'></audio>|AutoVC + WaveNet <span class='alignright'>(1039.64s)</span> <br> <audio controls><source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p226_003xp225_wavenet_chunked.wav'></audio> New AutoVC + MelGAN <span class='alignright'>(2.10s)</span><br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p226_003xp225_new_melgan.wav'>|
||Wouter (Male) <br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/Wouter_this_is_a_testsentence.wav'></audio>| AutoVC + WaveNet <span class='alignright'>(905.23s)</span> <br> <audio controls><source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p225_003xWouter_wavenet.wav'></audio> New AutoVC + MelGAN <span class='alignright'>(1.92s)</span><br> <audio controls> <source src='https://raw.githubusercontent.com/Woutah/API/gh-pages/samples/p226_003xWouter_new_melgan.wav'></audio>|
||225 (Female)|



